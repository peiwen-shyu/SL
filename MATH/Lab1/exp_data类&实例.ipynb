{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建exp_data类，用于处理实验数据，包括数据加载、降维、聚类和可视化等功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import leidenalg\n",
    "import igraph as ig\n",
    "\n",
    "from scipy.linalg import eigh\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exp_data():\n",
    "    '''\n",
    "    exp_data类用于处理实验数据，包括数据加载、降维、聚类和可视化等功能。\n",
    "    \n",
    "    属性:\n",
    "    name (str): 数据集名称。\n",
    "    data_mtx (ndarray): 数据矩阵。\n",
    "    real_labels (ndarray): 真实标签。\n",
    "    pc (ndarray): 降维后的数据。\n",
    "    pca_method (str): 使用的降维方法。\n",
    "    cluster_labels (ndarray): 聚类标签。\n",
    "    cluster_method (str): 使用的聚类方法。\n",
    "    silhouette_score (float): 轮廓系数。\n",
    "    ari_score (float): ARI）得分。\n",
    "    nmi_score (float): （NMI）得分。\n",
    "    方法:\n",
    "    __init__(self, name) -> None:\n",
    "        初始化exp_data类的实例。\n",
    "    load_data(self):\n",
    "        加载数据集和标签，并进行标准化处理。\n",
    "    pca(self, method_name=\"pca\", n_components=3, kernel='poly', degree=1, gamma=1, n_neighbors=10, init=\"random\", perplexity=30, n_iter=800):\n",
    "        使用不同的降维方法对数据进行降维。\n",
    "    compute_silhouette_score(self, clustered=False):\n",
    "        计算轮廓系数。\n",
    "    plot(self, clustered=False):\n",
    "        绘制降维后的数据散点图。\n",
    "    kmeans_clustering(self, n_clusters=None):\n",
    "        使用K均值算法对数据进行聚类。\n",
    "    leiden_clustering(self, n_neighbors=5):\n",
    "        使用Leiden算法对数据进行聚类。\n",
    "    mclustering(self, model_name=\"gmm\"):\n",
    "        使用高斯混合模型（GMM）或贝叶斯高斯混合模型（BGMM）对数据进行聚类。\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, name) -> None:\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.data_mtx = None\n",
    "        self.real_lables = None\n",
    "        self.pc = None\n",
    "        self.pca_method = None\n",
    "        self.cluster_labels = None\n",
    "        self.cluster_method = None\n",
    "        self.silhouette_score = None\n",
    "        self.ari_score = None\n",
    "        self.nmi_score = None\n",
    "\n",
    "    def load_data(self):\n",
    "\n",
    "        name = self.name\n",
    "        # 读取数据\n",
    "        df = pd.read_csv(filepath_or_buffer= paths[name], index_col=0)\n",
    "        # 读取标签\n",
    "        color_labels_path = ans_paths[name]\n",
    "        color_labels_df = pd.read_csv(color_labels_path, index_col=0, header=None)\n",
    "        label_encoder = LabelEncoder()\n",
    "        real_lable = label_encoder.fit_transform(color_labels_df.index)\n",
    "        # 标准化数据\n",
    "        # 认为是稀疏的，with_mean=False\n",
    "        data_mtx_std = StandardScaler(with_mean = False).fit_transform(df.values.T)\n",
    "\n",
    "        # 读取数据    \n",
    "        self.data_mtx = data_mtx_std.T\n",
    "        self.real_labels = real_lable\n",
    "\n",
    "        print(f\"已读取{name}数据集,样本数为:{df.values.shape[1]},特征数为:{df.values.shape[0]}\")\n",
    "\n",
    "    def pca(self,method_name = \"pca\", n_components=3, kernel='poly', degree=1, gamma=1, n_neighbors=10, init=\"random\", perplexity=30, n_iter=800):\n",
    "        \"\"\"\n",
    "        使用不同的降维方法对数据进行降维。\n",
    "        参数：\n",
    "        method_name (str): 降维方法的名称，可选值包括 'pca', 'kpca', 'isomap', 'lle', 'fica', 'fa', 'tsvd', 'se'，默认为 'pca'。\n",
    "        kernel (str): 核函数类型，仅在使用 'kpca' 方法时有效，可选值为 'poly' 或 'rbf'，默认为 'poly'。\n",
    "        degree (int): 多项式核函数的度数，仅在使用 'kpca' 方法时有效，默认为1。\n",
    "        gamma (float): RBF核函数的参数，仅在使用 'kpca' 方法时有效，默认为1。\n",
    "        n_neighbors (int): 每个点的邻居数，仅在使用 'isomap' 和 'lle' 方法时有效，默认为5。\n",
    "        init (str): 初始化方法，仅在使用 'tsne' 方法时有效，默认为 'random'，可选值为 'pca'。\n",
    "        perplexity (float): 有效邻居点数量，仅在使用 'tsne' 方法时有效，默认为30。\n",
    "        n_iter (int): 迭代次数，仅在使用 'tsne' 方法时有效，默认为800。\n",
    "        \n",
    "        该函数会更新对象的属性 self.pc 和 self.pca_method，分别保存降维后的数据和使用的降维方法。\n",
    "        \"\"\"\n",
    "        data_mtx = self.data_mtx\n",
    "        real_lable = self.real_labels\n",
    "        kernel = kernel\n",
    "        deg = degree\n",
    "        gam = gamma\n",
    "        n_neighbors = n_neighbors\n",
    "        init = init\n",
    "        perplexity = perplexity\n",
    "        n_iter = n_iter\n",
    "\n",
    "        # 子函数参数通过父函数参数传入\n",
    "\n",
    "        def fa():\n",
    "            \"\"\"\n",
    "            使用因子分析（Factor Analysis）进行降维。\n",
    "            参数:\n",
    "            n_components (int): 降维后的目标维数，默认为3。\n",
    "            返回:\n",
    "            tuple: 包含降维后的数据和PCA类型的元组。\n",
    "            \"\"\"\n",
    "            pca_type = 'Factor Analysis'\n",
    "            fa = FactorAnalysis(n_components=n_components, random_state=0)\n",
    "            data_fa = fa.fit_transform(data_mtx.T)\n",
    "            print(\"principal_components Shape:\",data_fa.shape)\n",
    "            return data_fa, pca_type\n",
    "\n",
    "        def fica():\n",
    "            \"\"\"\n",
    "            使用独立成分分析（FastICA）进行降维。\n",
    "            参数:\n",
    "            n_components (int): 降维后的目标维数，默认为3。\n",
    "            返回:\n",
    "            tuple: 包含以下两个元素的元组：\n",
    "                - data_fica (ndarray): 降维后的数据矩阵。\n",
    "                - pca_type (str): 降维方法的类型，固定为'Fast Independent Component Analysis'。\n",
    "            \"\"\"\n",
    "            pca_type = 'Fast Independent Component Analysis'\n",
    "            fica = FastICA(n_components=n_components, random_state=42,whiten='unit-variance')\n",
    "            data_fica = fica.fit_transform(data_mtx.T)\n",
    "            print(\"principal_components Shape:\",data_fica.shape)\n",
    "            return data_fica, pca_type\n",
    "\n",
    "        def lpca():\n",
    "            \"\"\"\n",
    "            执行主成分分析（PCA）并返回降维后的数据和PCA类型。\n",
    "            参数:\n",
    "            n_components (int): 要保留的主成分数量，默认为3。\n",
    "            返回:\n",
    "            tuple: 包含降维后的数据和PCA类型的元组。\n",
    "            \"\"\"    \n",
    "            pca_type = 'Linear'\n",
    "            pca = PCA(n_components=n_components)\n",
    "            data_linear_pca = pca.fit_transform(data_mtx.T)\n",
    "            print(\"principal_components Shape:\",data_linear_pca.shape)\n",
    "            return data_linear_pca,pca_type\n",
    "\n",
    "        def kpca():\n",
    "            \"\"\"\n",
    "            使用核主成分分析（Kernel PCA）进行降维。\n",
    "            参数:\n",
    "            n_components (int): 选择的主成分数量，默认值为3。\n",
    "            kernel (str): 核函数类型，可以是 'rbf' 或 'poly'，默认值为 'poly'。\n",
    "            degree (int): 多项式核函数的度数，默认值为1。\n",
    "            gamma (float): RBF核函数的参数，默认值为1。\n",
    "            返回:\n",
    "            tuple: 包含降维后的数据和PCA类型的元组。\n",
    "            \"\"\"\n",
    "            pca_type = 'Kernel'\n",
    "            degree = deg \n",
    "            gamma = gam \n",
    "            print(f\"Computing polomial kernel matrix with degree = {degree} and RBF kernel of gamma = {gamma}...\")\n",
    "            K_poly = polynomial_kernel(data_mtx.T, degree=degree)\n",
    "            K_rbf = rbf_kernel(data_mtx.T, gamma=gamma)\n",
    "            print(\"RBF and polynomial kernel matrix computed.\")\n",
    "\n",
    "            # 对应核函数的核矩阵\n",
    "            if kernel == 'poly':\n",
    "                K = K_poly\n",
    "            elif kernel == 'rbf':\n",
    "                K = K_rbf\n",
    "\n",
    "            # Center the kernel matrix\n",
    "            ones = np.ones(K.shape) / K.shape[0]\n",
    "            K_centered= K - ones @ K - K @ ones + ones @ K @ ones\n",
    "            print(\"Kernel matrix centered.\")\n",
    "\n",
    "            # Compute largest k eigenvalues of kernel matrix\n",
    "            k = n_components\n",
    "            print(f\"Computing the first {k} largest eigenvalues and eigenvectors...\")\n",
    "            # eigh returns eigenvalues in ascending order, so we need to get the last k\n",
    "            eigenvalues, eigenvectors = eigh(K_centered, eigvals=(K_centered.shape[0]-k, K_centered.shape[0]-1))\n",
    "            print(\"Eigenvalue decomposition completed.\")\n",
    "            print(f\"First {k} eigenvalues represent {sum(eigenvalues)/K_centered.trace()} of all features\")\n",
    "\n",
    "            data_k_pca = eigenvectors\n",
    "\n",
    "            return data_k_pca, pca_type\n",
    "\n",
    "        def isomap():\n",
    "            \"\"\"\n",
    "            使用等距特征映射（Isomap）进行降维。\n",
    "            参数:\n",
    "            n_components (int): 降维后的目标维数，默认值为3。\n",
    "            n_neighbors (int): 每个点的邻居数，默认值为200。\n",
    "            返回:\n",
    "            tuple: 包含以下两个元素的元组：\n",
    "                - data_isomap (ndarray): 降维后的数据矩阵。\n",
    "                - pca_type (str): 降维方法的类型，固定为'Isomap'。\n",
    "            \"\"\"\n",
    "            pca_type = 'Isomap'\n",
    "            # Perform Isometric Feature Mapping (Isomap)\n",
    "            isomap = Isomap(n_neighbors=n_neighbors, n_components=n_components)\n",
    "            data_isomap = isomap.fit_transform(data_mtx.T)\n",
    "\n",
    "            # print(\"Isomap completed.\")\n",
    "            print(\"principal_components Shape:\", data_isomap.shape)\n",
    "            return data_isomap, pca_type\n",
    "\n",
    "        def lle():\n",
    "            \"\"\"\n",
    "            局部线性嵌入 (Locally Linear Embedding)，该非线性降维方法结果具有随机性。\n",
    "            参数:\n",
    "            n_components (int): 嵌入空间的维数，默认为3。\n",
    "            n_neighbors (int): 每个点的邻居数量，默认为5。\n",
    "            返回:\n",
    "            tuple: 包含以下两个元素的元组\n",
    "                - data_lle (ndarray): 经过局部线性嵌入后的数据矩阵。\n",
    "                - pca_type (str): 表示PCA类型的字符串，值为 'Locally Linear Embedding'。\n",
    "            \"\"\"\n",
    "\n",
    "            \"\"\"Locally Linear Embedding\"\"\"\n",
    "            pca_type = 'Locally Linear Embedding'\n",
    "            lle = LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_components, random_state=40)\n",
    "            data_lle = lle.fit_transform(data_mtx.T)\n",
    "            print(\"primcipal_components Shape:\", data_lle.shape)\n",
    "            return data_lle, pca_type\n",
    "\n",
    "    \n",
    "        def se():\n",
    "            \"\"\"\n",
    "            使用谱嵌入（Spectral Embedding）进行降维。\n",
    "            参数:\n",
    "            n_components (int): 降维后的目标维数，默认为3。\n",
    "            返回:\n",
    "            tuple: 包含降维后的数据和PCA类型的元组。\n",
    "            \"\"\"\n",
    "            pca_type = 'Spectral Embedding'\n",
    "            se = SpectralEmbedding(n_components=n_components, random_state=40)\n",
    "            data_se = se.fit_transform(data_mtx.T)\n",
    "            print(\"principal_components Shape:\",data_se.shape)\n",
    "            return data_se, pca_type\n",
    "\n",
    "        pca_functions = {\"pca\":lpca, \"kpca\":kpca, \"isomap\":isomap, \"lle\":lle, \"fica\":fica, \"fa\":fa, \"se\":se}\n",
    "        # 保存主成分\n",
    "        pca_func = pca_functions[method_name]\n",
    "        self.pc, remark = pca_func()\n",
    "        self.pca_method = pca_func.__name__\n",
    "        \n",
    "        print(f\"使用{pca_func.__name__}方法,注：{remark}\")\n",
    "        \n",
    "    \n",
    "    def compute_silhouette_score(self,clustered=False):\n",
    "        \"\"\"\n",
    "        计算轮廓系数。\n",
    "        参数:\n",
    "        \n",
    "        \"\"\"\n",
    "        data = self.pc\n",
    "        # real为默认为真，计算真实标签下的轮廓系数，否则计算聚类标签下的轮廓系数\n",
    "        if clustered:\n",
    "            label = self.cluster_labels\n",
    "        else:\n",
    "            label = self.real_labels\n",
    "        score = silhouette_score(data, label)\n",
    "        self.silhouette_score = score\n",
    "\n",
    "        return score\n",
    "\n",
    "    def plot(self,clustered=False):\n",
    "        \"\"\"\n",
    "        绘制降维后的数据散点图,细胞依据给定的类别用不同颜色表示，呈现分散效果。\n",
    "        参数:\n",
    "        pca_func (tuple): 包含降维后的数据和PCA类型的元组。\n",
    "        clustered (bool): 是否使用聚类标签，默认为False。\n",
    "        \"\"\"\n",
    "        # 创建图形和3D坐标轴\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        data = self.pc\n",
    "        \n",
    "        if clustered:\n",
    "            color_label = self.cluster_labels\n",
    "        else:\n",
    "            color_label = self.real_labels\n",
    "\n",
    "        # 绘制散点图\n",
    "        scatter = ax.scatter(data[:, 0], data[:, 1], data[:, 2], c=color_label, cmap='viridis', s=4)\n",
    "\n",
    "        # 完全隐藏坐标\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def kmeans_clustering(self, n_clusters=None):\n",
    "        \"\"\"\n",
    "        使用K均值算法对数据进行聚类。\n",
    "        参数:\n",
    "        n_clusters (int): 聚类数，默认为None。\n",
    "        返回:\n",
    "        无返回值。该方法会更新以下实例属性：\n",
    "        - self.cluster_labels: 聚类标签。\n",
    "        - self.cluster_method: 聚类方法名称，固定为 'kmeans'。\n",
    "        - self.ari_score: 调整兰德指数（ARI）得分。\n",
    "        - self.nmi_score: 归一化互信息（NMI）得分。\n",
    "        \"\"\"\n",
    "        real_lable = self.real_labels\n",
    "        # 真实标签细胞种类数作为聚类数\n",
    "        n_clusters = real_lable.max() + 1\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(self.pc)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # 计算（ARI）得分\n",
    "        ari_score = adjusted_rand_score(real_lable, labels)\n",
    "        # print(f\"ARI 分数为: {ari_score}\")\n",
    "\n",
    "        # 计算（NMI）得分\n",
    "        nmi_score = normalized_mutual_info_score(real_lable, labels)\n",
    "        # print(f\"NMI 分数为: {nmi_score}\")\n",
    "        \n",
    "        self.cluster_labels = labels\n",
    "        self.cluster_method = 'kmeans'\n",
    "        self.ari_score = ari_score\n",
    "        self.nmi_score = nmi_score\n",
    "\n",
    "\n",
    "    def leiden_clustering(self, n_neighbors=5):\n",
    "        \"\"\"\n",
    "            使用Leiden算法对数据进行聚类。\n",
    "            参数:\n",
    "            n_neighbors (int): 每个点的邻居数，默认为5。\n",
    "            返回:\n",
    "            无返回值。该方法会更新以下实例属性：\n",
    "            - self.cluster_labels: 聚类标签。\n",
    "            - self.cluster_method: 聚类方法名称，固定为 'leiden'。\n",
    "            - self.ari_score: 调整兰德指数（ARI）得分。\n",
    "            - self.nmi_score: 归一化互信息（NMI）得分。\n",
    "            \"\"\"\n",
    "        real_lable = self.real_labels\n",
    "\n",
    "        knn_graph = kneighbors_graph(self.pc, n_neighbors=n_neighbors, include_self=False)\n",
    "        sources, targets = knn_graph.nonzero()\n",
    "        edges = list(zip(sources, targets))\n",
    "        G = ig.Graph(edges=edges, directed=False)\n",
    "\n",
    "        partition = leidenalg.find_partition(G, partition_type=leidenalg.RBConfigurationVertexPartition, seed=42)\n",
    "\n",
    "        labels = np.array(partition.membership)\n",
    "        \n",
    "        # 计算（ARI）得分\n",
    "        ari_score = adjusted_rand_score(real_lable, labels)\n",
    "        # print(f\"ARI 分数为: {ari_score}\")\n",
    "\n",
    "        # 计算（NMI）得分\n",
    "        nmi_score = normalized_mutual_info_score(real_lable, labels)\n",
    "        # print(f\"NMI 分数为: {nmi_score}\")\n",
    "        \n",
    "        self.cluster_labels = labels\n",
    "        self.cluster_method = 'leiden'\n",
    "        self.ari_score = ari_score\n",
    "        self.nmi_score = nmi_score\n",
    "\n",
    "\n",
    "\n",
    "    def mclustering(self, model_name = \"gmm\"):\n",
    "        def mclustering(self, model_name=\"gmm\"):\n",
    "            \"\"\"\n",
    "            使用高斯混合模型（GMM）或贝叶斯高斯混合模型（BGMM）对数据进行聚类。\n",
    "            参数:\n",
    "            model_name (str): 指定使用的模型名称，可以是 \"gmm\" 或 \"bgmm\"。默认为 \"gmm\"。\n",
    "            返回:\n",
    "            无返回值。该方法会更新以下实例属性：\n",
    "            - self.cluster_labels: 聚类标签。\n",
    "            - self.cluster_method: 聚类方法名称，固定为 'mclust'。\n",
    "            - self.ari_score: 调整兰德指数（ARI）得分。\n",
    "            - self.nmi_score: 归一化互信息（NMI）得分。\n",
    "            \"\"\"\n",
    "        real_lable = self.real_labels\n",
    "\n",
    "        X = self.pc\n",
    "\n",
    "        gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=0)\n",
    "        bgmm = BayesianGaussianMixture(n_components=3, covariance_type='full', random_state=0)\n",
    "\n",
    "        models = {\"gmm\":gmm, \"bgmm\":bgmm}\n",
    "        model = models[model_name] \n",
    "        model.fit(X)\n",
    "\n",
    "        labels = model.predict(X)\n",
    "\n",
    "        centroids = model.means_\n",
    "         \n",
    "\n",
    "        # 计算 (ARI) 得分 \n",
    "        ari_score = adjusted_rand_score(real_lable, labels)\n",
    "        # print(f\"ARI 分数为： {ari_score}\")\n",
    "\n",
    "        # 计算 (NMI) 得分\n",
    "        nmi_score = normalized_mutual_info_score(real_lable, labels)\n",
    "        # print(f\"NMI 分数为： {nmi_score}\")\n",
    "\n",
    "        self.cluster_labels = labels\n",
    "        self.cluster_method = 'mclust'\n",
    "        self.ari_score = ari_score\n",
    "        self.nmi_score = nmi_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp_data类实例与运用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 数据集路径\n",
    "paths = {'deng':'./set2/deng.logcounts.csv','seger':'./set3/seger.logcounts.csv','zeisel':'./set4/zeisel.logcounts.csv'}\n",
    "ans_paths = {'deng':'./set2/set2.ans.csv','seger':'./set3/set3.ans.csv','zeisel':'./set4/set4.ans.csv'}\n",
    "\n",
    "# 三个数据集的名字 ['deng','seger','zeisel']\n",
    "\n",
    "exp_deng = exp_data(\"deng\")\n",
    "exp_deng.load_data()\n",
    "# exp_seger = exp_data(\"seger\")\n",
    "# exp_seger.load_data()\n",
    "# exp_zeisel = exp_data(\"zeisel\")\n",
    "# exp_zeisel.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用PCA方法对数据进行降维,得到轮廓系数，并绘制散点图\n",
    "exp_deng.pca(method_name=\"pca\")\n",
    "exp_deng.plot()\n",
    "print(\"线性PCA轮廓系数：\",exp_deng.compute_silhouette_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用LLE对数据进行降维,得到轮廓系数，并绘制散点图\n",
    "exp_deng.pca(method_name=\"lle\",n_neighbors=79)\n",
    "exp_deng.plot()\n",
    "print(\"LLE轮廓系数：\",exp_deng.compute_silhouette_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看目前实例的PCA方法\n",
    "print(exp_deng.pca_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用不同的聚类方法对数据进行聚类\n",
    "exp_deng.kmeans_clustering()\n",
    "exp_deng.plot(clustered=True)\n",
    "print(\"Kmeans轮廓系数：\",exp_deng.compute_silhouette_score(clustered=True))\n",
    "print(\"Kmeans ARI分数：\",exp_deng.ari_score)\n",
    "print(\"Kmeans NMI分数：\",exp_deng.nmi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Leiden算法对数据进行聚类\n",
    "exp_deng.leiden_clustering(n_neighbors=110)\n",
    "exp_deng.plot(clustered=True)\n",
    "print(\"Leiden轮廓系数：\",exp_deng.compute_silhouette_score(clustered=True))\n",
    "print(\"Leiden ARI:\",exp_deng.ari_score)\n",
    "print(\"Leiden NMI:\",exp_deng.nmi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用mclust对数据进行聚类\n",
    "exp_deng.mclustering(model_name=\"gmm\")\n",
    "exp_deng.plot(clustered=True)\n",
    "print(f\"{model_name}轮廓系数：\",exp_deng.compute_silhouette_score(clustered=True))\n",
    "print(f\"{model_name} ARI:\",exp_deng.ari_score)\n",
    "print(f\"{model_name} NMI:\",exp_deng.nmi_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
